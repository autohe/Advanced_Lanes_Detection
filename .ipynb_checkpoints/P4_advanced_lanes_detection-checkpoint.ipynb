{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Advanced Lanes Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in and make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function cal_undistort takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function makes sure that each processed image is saved in the \n",
    "# appropriate folder \n",
    "def save_img(img, folder, fname, stage_name, col_map):\n",
    "    fname = fname.split('/')[1]\n",
    "    fname = fname.split('.')[0]\n",
    "    new_filename = fname + \"_\" + stage_name + '.jpg'    \n",
    "    mpimg.imsave(folder + \"/\" + new_filename, img,cmap=col_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images\n",
    "\n",
    "objpoints = [] # 3D points in real world space\n",
    "imgpoints = [] # 2D points in image plane \n",
    "\n",
    "# Prepare object points \n",
    "objp = np.zeros((6*9,3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # x,y coordinates\n",
    "\n",
    "# Create the undistorted_images directory within the camera_cal directory\n",
    "if not os.path.exists(\"camera_cal/undistorted_images\"):\n",
    "    os.makedirs(\"camera_cal/undistorted_images\")\n",
    "\n",
    "for fname in images:\n",
    "    # read in each image\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "    \n",
    "    # If corners are found, add object and image points \n",
    "    if ret == True:\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "        \n",
    "        # draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        \n",
    "        # get the undistorted version of the calibration image\n",
    "        undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "        \n",
    "        save_img(undistorted, \"camera_cal/undistorted_images\", fname, \"undist\", col_map = 'jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Computer Vision Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(warped, window_width, window_height, margin):\n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(warped.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(warped.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,warped.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,warped.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the undistorted directory \n",
    "if not os.path.exists(\"output_images/undistorted\"):\n",
    "    os.makedirs(\"output_images/undistorted\")\n",
    "# Create the binary directory \n",
    "if not os.path.exists(\"output_images/binary\"):\n",
    "    os.makedirs(\"output_images/binary\")\n",
    "# Create the warped directory \n",
    "if not os.path.exists(\"output_images/warped\"):\n",
    "    os.makedirs(\"output_images/warped\")\n",
    "# Create the lane_pixels directory \n",
    "if not os.path.exists(\"output_images/lane_pixels\"):\n",
    "    os.makedirs(\"output_images/lane_pixels\")\n",
    "# Create the polynomial directory \n",
    "if not os.path.exists(\"output_images/polynomial\"):\n",
    "    os.makedirs(\"output_images/polynomial\")\n",
    "\n",
    "    \n",
    "# This function processes each individual image coming from the video stream \n",
    "# and estimates where the lane lines are\n",
    "def image_pipeline(img, fname):\n",
    "    undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "    save_img(undistorted, \"output_images/undistorted\", fname, \"undistorted\", col_map = 'jet')\n",
    "    \n",
    "    s_thresh=(170, 255)\n",
    "    sx_thresh=(20, 100)\n",
    "    \n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    \n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    binary_final = sxbinary + s_binary\n",
    "    save_img(binary_final, \"output_images/binary\", fname, \"binary\", col_map = 'gray')\n",
    "    \n",
    "    # Apply a birds-eye view's perspective transform\n",
    "    src = np.float32([[585, 460],[203, 720],[1127, 720],[695, 460]])\n",
    "    dst = np.float32([[320, 0],[320, 720],[960, 720],[960, 0]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    img_size = (binary_final.shape[1],binary_final.shape[0])\n",
    "    warped = cv2.warpPerspective(binary_final, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    save_img(warped, \"output_images/warped\", fname, \"warped\", col_map = 'gray')\n",
    "    \n",
    "    # Apply a sliding window search\n",
    "    # window settings\n",
    "    window_width = 50 \n",
    "    window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "    margin = 100 # How much to slide left and right for searching\n",
    "    window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "    # If we found any window centers\n",
    "    if len(window_centroids) > 0:\n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(warped)\n",
    "        r_points = np.zeros_like(warped)\n",
    "\n",
    "        # Go through each level and draw the windows \t\n",
    "        for level in range(0,len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channle \n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results \n",
    "    # If no window centers found, just display orginal road image\n",
    "    else:\n",
    "        output = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "    save_img(output, \"output_images/lane_pixels\", fname, \"lane_pixels\", col_map = 'jet')\n",
    "    \n",
    "    # Apply polynomial fits to the left and right lanes\n",
    "    if len(window_centroids) > 0:\n",
    "        leftx = []\n",
    "        lefty = []\n",
    "        for (x,y), value in np.ndenumerate(l_points):\n",
    "            if l_points[x,y] == 255:\n",
    "                leftx.append(y)\n",
    "                lefty.append(x)\n",
    "        rightx = []\n",
    "        righty = []\n",
    "        for (x,y), value in np.ndenumerate(r_points):\n",
    "            if r_points[x,y] == 255:\n",
    "                rightx.append(y)\n",
    "                righty.append(x) \n",
    "        \n",
    "        lefty = lefty[::-1]\n",
    "        righty = righty[::-1]\n",
    "    \n",
    "        ploty = np.linspace(0, 719, num=720)\n",
    "        left_fit = np.polyfit(lefty, leftx, 2) \n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        mark_size = 3\n",
    "        plt.plot(leftx, lefty, 'o', color='red', markersize=mark_size)\n",
    "        plt.plot(rightx, righty, 'o', color='blue', markersize=mark_size)\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(0, 720)\n",
    "        plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "        fit_image = plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "        plt.gca().invert_yaxis() \n",
    "        save_img(fit_image, \"output_images/polynomial\", fname, \"polynomial\", col_map = 'jet')\n",
    "         \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the output_images directory \n",
    "if not os.path.exists(\"output_images\"):\n",
    "    os.makedirs(\"output_images\")\n",
    "    \n",
    "# Read in and make a list of the test images\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in test_images:\n",
    "    # read in each image\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "    result = image_pipeline(img, fname)\n",
    "    \n",
    "    save_img(result, \"output_images\", fname, \"final\", col_map = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
